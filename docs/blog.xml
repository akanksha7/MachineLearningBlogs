<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Akanksha Singh</title>
<link>https://akanksha-singh.us/blog.html</link>
<atom:link href="https://akanksha-singh.us/blog.xml" rel="self" type="application/rss+xml"/>
<description>This is Akanksha Singh&#39;s personal blog</description>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Tue, 05 Dec 2023 05:00:00 GMT</lastBuildDate>
<item>
  <title>Post With Code</title>
  <dc:creator>Harlow Malloc</dc:creator>
  <link>https://akanksha-singh.us/posts/Anomaly/Outlier Detection/index.html</link>
  <description><![CDATA[ 



<p>This is a post with executable code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
</div>



 ]]></description>
  <category>news</category>
  <category>code</category>
  <category>analysis</category>
  <guid>https://akanksha-singh.us/posts/Anomaly/Outlier Detection/index.html</guid>
  <pubDate>Tue, 05 Dec 2023 05:00:00 GMT</pubDate>
  <media:content url="https://akanksha-singh.us/posts/Anomaly/Outlier Detection/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Post With Code</title>
  <dc:creator>Harlow Malloc</dc:creator>
  <link>https://akanksha-singh.us/posts/Classification/index.html</link>
  <description><![CDATA[ 



<p>This is a post with executable code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
</div>



 ]]></description>
  <category>news</category>
  <category>code</category>
  <category>analysis</category>
  <guid>https://akanksha-singh.us/posts/Classification/index.html</guid>
  <pubDate>Tue, 05 Dec 2023 05:00:00 GMT</pubDate>
  <media:content url="https://akanksha-singh.us/posts/Classification/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Post With Code</title>
  <dc:creator>Harlow Malloc</dc:creator>
  <link>https://akanksha-singh.us/posts/Probability Theory and Random Variables/index.html</link>
  <description><![CDATA[ 



<p>This is a post with executable code.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span> <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span></span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2</code></pre>
</div>
</div>



 ]]></description>
  <category>news</category>
  <category>code</category>
  <category>analysis</category>
  <guid>https://akanksha-singh.us/posts/Probability Theory and Random Variables/index.html</guid>
  <pubDate>Tue, 05 Dec 2023 05:00:00 GMT</pubDate>
  <media:content url="https://akanksha-singh.us/posts/Probability Theory and Random Variables/image.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Unveiling Relationships in Data: A Journey through Linear and Nonlinear Regression</title>
  <dc:creator>Akanksha Singh</dc:creator>
  <link>https://akanksha-singh.us/posts/Linear and Non-Linear Regression/index.html</link>
  <description><![CDATA[ 



<p>In the realm of data science, regression analysis stands as a cornerstone technique for understanding the relationships between variables. It enables us to quantify the association between an independent variable (or predictor) and a dependent variable (or response), shedding light on the underlying patterns and trends within data. Regression analysis can be broadly categorized into two main types: linear and nonlinear. Linear regression assumes a straight-line relationship between the independent and dependent variables, while nonlinear regression caters to more complex relationships that may involve curves or other non-linear patterns.</p>
<p>In this blog post, we’ll embark on a journey to explore both linear and nonlinear regression using R, employing public datasets to illustrate their applications. We’ll delve into the code and visualizations, unraveling the intricacies of these regression techniques and their ability to uncover hidden insights from data.</p>
<section id="linear-regression-a-foundation-for-understanding-linear-relationships" class="level2">
<h2 class="anchored" data-anchor-id="linear-regression-a-foundation-for-understanding-linear-relationships"><strong>Linear Regression: A Foundation for Understanding Linear Relationships</strong></h2>
<p>Linear regression, the simpler of the two, assumes a linear relationship between the independent variable (X) and the dependent variable (Y). It models the relationship as a straight line, represented by the equation:</p>
<pre><code>Y = β0 + β1X + ε</code></pre>
<p>where:</p>
<ul>
<li><p><code>Y</code> is the dependent variable</p></li>
<li><p><code>X</code> is the independent variable</p></li>
<li><p><code>β0</code> is the intercept, representing the value of Y when X is zero</p></li>
<li><p><code>β1</code> is the slope, indicating the change in Y for a one-unit change in X</p></li>
<li><p><code>ε</code> is the error term, representing the random variation not explained by the model</p></li>
</ul>
<p>Linear regression is a powerful tool for understanding linear relationships between variables. It provides insights into the direction and strength of the association, allowing us to make predictions about the dependent variable based on the independent variable.</p>
<section id="linear-regression-in-action-predicting-fuel-consumption-from-engine-size" class="level3">
<h3 class="anchored" data-anchor-id="linear-regression-in-action-predicting-fuel-consumption-from-engine-size"><strong>Linear Regression in Action: Predicting Fuel Consumption from Engine Size</strong></h3>
<p>The <code>mtcars</code> dataset, included in the <code>base</code> package of R, provides information about the fuel consumption and other characteristics of 32 model cars. We can use this data to explore the relationship between fuel consumption (mpg) and engine size (disp), hypothesizing that there might be a negative correlation between the two variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the mtcars dataset</span></span>
<span id="cb2-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(mtcars)</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform linear regression to predict Fuel Consumption (mpg) based on Engine Size (disp)</span></span>
<span id="cb2-5">model <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lm</span>(mpg <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> disp, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> mtcars)</span>
<span id="cb2-6"></span>
<span id="cb2-7"></span>
<span id="cb2-8"></span>
<span id="cb2-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Summarize the regression model</span></span>
<span id="cb2-10"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summary</span>(model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ disp, data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.8922 -2.2022 -0.9631  1.6272  7.2305 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 29.599855   1.229720  24.070  &lt; 2e-16 ***
disp        -0.041215   0.004712  -8.747 9.38e-10 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.251 on 30 degrees of freedom
Multiple R-squared:  0.7183,    Adjusted R-squared:  0.709 
F-statistic: 76.51 on 1 and 30 DF,  p-value: 9.38e-10</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a scatter plot with the fitted regression line</span></span>
<span id="cb4-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(mtcars<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>disp, mtcars<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>mpg)</span>
<span id="cb4-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">abline</span>(model<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>coefficients)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://akanksha-singh.us/posts/Linear and Non-Linear Regression/index_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This code block performs linear regression using the <code>lm()</code> function from the <code>stats</code> package. The formula <code>mpg ~ disp</code> specifies the dependent variable (mpg) and the independent variable (disp). The <code>data = mtcars</code> argument indicates that the analysis should be conducted on the <code>mtcars</code> dataset. The result of this line is stored in the <code>model</code> object.</p>
<p>The <code>summary()</code> function provides information about the estimated coefficients for the intercept and slope, as well as their standard errors and p-values. It also provides overall statistics about the model fit, such as the R-squared value and the adjusted R-squared value.</p>
<p>The <code>plot()</code> function creates a scatter plot of Fuel Consumption (mpg) versus Engine Size (disp). The <code>abline()</code> function adds the fitted regression line to the scatter plot. The coefficients for the line are extracted from the <code>model$coefficients</code> object.</p>
</section>
<section id="visualizing-the-linear-relationship" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-linear-relationship"><strong>Visualizing the Linear Relationship:</strong></h3>
<p>The scatter plot clearly depicts the linear pattern between Fuel Consumption and Engine Size, with the regression line capturing the overall trend. The negative slope of the line indicates that as engine size increases, fuel consumption decreases.</p>
</section>
</section>
<section id="nonlinear-regression-capturing-complex-relationships" class="level2">
<h2 class="anchored" data-anchor-id="nonlinear-regression-capturing-complex-relationships"><strong>Nonlinear Regression: Capturing Complex Relationships</strong></h2>
<p>When data exhibits a nonlinear relationship, linear regression falls short. Nonlinear regression techniques, such as polynomial regression, allow us to model more complex relationships between variables.</p>
<p>Polynomial regression involves fitting a polynomial function of the independent variable to the dependent variable. The degree of the polynomial determines the complexity of the curve.</p>
<section id="visualizing-the-nonlinear-relationship" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-nonlinear-relationship"><strong>Visualizing the Nonlinear Relationship:</strong></h3>
<p>Using the <code>mtcars</code> dataset, we can explore the relationship between Horsepower and Fuel Consumption, which may not be linear.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform polynomial regression with a quadratic term</span></span>
<span id="cb5-2">model <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lm</span>(mpg <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> hp <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">I</span>(hp<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">^</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">data =</span> mtcars)</span>
<span id="cb5-3"></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Summarize the regression model</span></span>
<span id="cb5-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summary</span>(model)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = mpg ~ hp + I(hp^2), data = mtcars)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5512 -1.6027 -0.6977  1.5509  8.7213 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  4.041e+01  2.741e+00  14.744 5.23e-15 ***
hp          -2.133e-01  3.488e-02  -6.115 1.16e-06 ***
I(hp^2)      4.208e-04  9.844e-05   4.275 0.000189 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.077 on 29 degrees of freedom
Multiple R-squared:  0.7561,    Adjusted R-squared:  0.7393 
F-statistic: 44.95 on 2 and 29 DF,  p-value: 1.301e-09</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a scatter plot with the fitted regression curve</span></span>
<span id="cb7-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(mtcars<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>hp, mtcars<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>mpg)</span>
<span id="cb7-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">lines</span>(mtcars<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>hp, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">predict</span>(model))</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://akanksha-singh.us/posts/Linear and Non-Linear Regression/index_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="section" class="level3">
<h3 class="anchored" data-anchor-id="section"></h3>
<p>The plot reveals a more complex relationship between Horsepower and Fuel Consumption, with a curve indicating a non-linear association. The initial increase in horsepower leads to a decrease in fuel consumption, but as horsepower continues to increase, fuel consumption starts to rise again.</p>
</section>
<section id="nonlinear-regression-a-path-to-unveiling-complex-patterns" class="level3">
<h3 class="anchored" data-anchor-id="nonlinear-regression-a-path-to-unveiling-complex-patterns"><strong>Nonlinear Regression: A Path to Unveiling Complex Patterns</strong></h3>
<p>Nonlinear regression techniques like polynomial regression provide a more versatile approach for modeling complex relationships between variables. They allow us to capture patterns that cannot be adequately represented by a straight line. This makes nonlinear regression a valuable tool for analyzing data that exhibits non-linear trends.</p>
<p>In addition to polynomial regression, there are various other nonlinear regression techniques, such as exponential regression and logarithmic regression. The choice of the appropriate nonlinear regression technique depends on the specific nature of the relationship between the independent and dependent variables.</p>
</section>
</section>
<section id="conclusion-unveiling-the-stories-hidden-in-data" class="level2">
<h2 class="anchored" data-anchor-id="conclusion-unveiling-the-stories-hidden-in-data"><strong>Conclusion: Unveiling the Stories Hidden in Data</strong></h2>
<p>Linear and nonlinear regression serve as powerful tools for understanding the relationships between variables in data. Linear regression provides a simple yet effective approach for linear relationships, while nonlinear regression caters to more intricate patterns. By exploring these regression techniques using R and public datasets, we’ve gained insights into their applications and capabilities.</p>
<p>Whether dealing with straightforward linear associations or complex nonlinear trends, regression analysis empowers us to uncover the hidden stories within data. By quantifying the relationships between variables, we can gain insights into the underlying mechanisms driving the behavior of systems and phenomena. As we continue to explore the vast realm of data science, regression analysis will remain a cornerstone technique, enabling us to transform raw data into meaningful knowledge.</p>


</section>

 ]]></description>
  <category>ml</category>
  <category>code</category>
  <category>analysis</category>
  <guid>https://akanksha-singh.us/posts/Linear and Non-Linear Regression/index.html</guid>
  <pubDate>Sat, 25 Nov 2023 05:00:00 GMT</pubDate>
  <media:content url="https://akanksha-singh.us/posts/Linear and Non-Linear Regression/regression.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Clustering:Unveiling Hidden Patterns in Data</title>
  <dc:creator>Akanksha Singh</dc:creator>
  <link>https://akanksha-singh.us/posts/Clustering/index.html</link>
  <description><![CDATA[ 



<p><strong>Clustering</strong> or <strong>cluster analysis</strong> is an unsupervised learning problem.</p>
<p>It is often used as a data analysis technique for discovering interesting patterns in data, such as groups of customers based on their behavior.It involves automatically discovering natural grouping in data. Unlike supervised learning (like predictive modeling), clustering algorithms only interpret the input data and find natural groups or clusters in feature space.</p>
<p>Unlike classification tasks, where data points are assigned to predefined categories, clustering algorithms seek to group data points based on their inherent similarities, revealing underlying relationships that might otherwise go unnoticed.</p>
<p>Clustering can be helpful as a data analysis activity in order to learn more about the problem domain, so-called pattern discovery or knowledge discovery.</p>
<p>For example:</p>
<ul>
<li><p>The <a href="https://en.wikipedia.org/wiki/Phylogenetic_tree">phylogenetic tree</a> could be considered the result of a manual clustering analysis.</p></li>
<li><p>Separating normal data from outliers or anomalies may be considered a clustering problem.</p></li>
<li><p>Separating clusters based on their natural behavior is a clustering problem, referred to as market segmentation.</p></li>
</ul>
<p>Clustering techniques can be broadly categorized into two main approaches: hierarchical and partitional clustering.</p>
<ul>
<li><p><strong>Hierarchical clustering</strong> algorithms construct a hierarchy of clusters, gradually merging or splitting data points based on their pairwise distances. This approach produces a nested tree-like structure, allowing for exploration of data at different levels of granularity.</p></li>
<li><p><strong>Partitional clustering</strong> algorithms, on the other hand, aim to partition the data into a predefined number of clusters. These algorithms typically employ an iterative approach, assigning data points to clusters and then refining the cluster assignments until a stable configuration is reached.</p></li>
</ul>
<section id="clustering-algorithms" class="level2">
<h2 class="anchored" data-anchor-id="clustering-algorithms">Clustering Algorithms</h2>
<ul>
<li><p>There are many types of clustering algorithms.</p>
<p>Many algorithms use similarity or distance measures between examples in the feature space in an effort to discover dense regions of observations. As such, it is often good practice to scale data prior to using clustering algorithms.</p>
<p>Some clustering algorithms require you to specify or guess at the number of clusters to discover in the data, whereas others require the specification of some minimum distance between observations in which examples may be considered “<em>close</em>” or “<em>connected</em>.”</p>
<p>As such, cluster analysis is an iterative process where subjective evaluation of the identified clusters is fed back into changes to algorithm configuration until a desired or appropriate result is achieved.</p>
<p>The scikit-learn library provides a suite of different clustering algorithms to choose from.</p>
<p>Here we will focus on these popular clustering algorithms:</p>
<ul>
<li><p>K-Means</p></li>
<li><p>Hierarchical</p>
<p>Each algorithm offers a different approach to the challenge of discovering natural groups in data.</p>
<p>There is no best clustering algorithm, and no easy way to find the best algorithm for your data without using controlled experiments.</p></li>
</ul></li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">options</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">repos =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">CRAN =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://repo.miserver.it.umich.edu/cran/"</span>))</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ggplot2"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
The downloaded binary packages are in
    /var/folders/rk/5lvxwjhj7y9_l0r83j1hx_rw0000gn/T//Rtmp9pocRv/downloaded_packages</code></pre>
</div>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span></code></pre></div>
</div>
<p>Let’s start by installing the necessary packages for data manipulation (dplyr), k-means clustering (kmeans), and hierarchical clustering (cluster). These packages provide the tools required to perform the clustering analysis and create visualizations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load required packages</span></span>
<span id="cb4-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"dplyr"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
The downloaded binary packages are in
    /var/folders/rk/5lvxwjhj7y9_l0r83j1hx_rw0000gn/T//Rtmp9pocRv/downloaded_packages</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"kmeans"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: package 'kmeans' is not available for this version of R

A version of this package for your version of R might be available elsewhere,
see the ideas at
https://cran.r-project.org/doc/manuals/r-patched/R-admin.html#Installing-packages</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install.packages</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cluster"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
The downloaded binary packages are in
    /var/folders/rk/5lvxwjhj7y9_l0r83j1hx_rw0000gn/T//Rtmp9pocRv/downloaded_packages</code></pre>
</div>
</div>
<p>This block loads the Wine dataset from the UCI Machine Learning Repository into the R environment. The read.csv() function reads the CSV file and stores the data in a data frame named data. The header = FALSE argument indicates that the first row of the CSV file does not contain column names.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the Wine dataset from the UCI Machine Learning Repository</span></span>
<span id="cb10-2">data <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read.csv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">header =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span></code></pre></div>
</div>
<p>Now we will assign some meaningful names to the columns of the data frame. The names(data) &lt;- c(…) syntax replaces the default column names with the specified ones. This makes the data more understandable and easier to work with.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Name the columns</span></span>
<span id="cb11-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">names</span>(data) <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"alcohol"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"malic_acid"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ash"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"alcalinity_ash"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"magnesium"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"total_phenols"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"flavanoids"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"nonflavanoids"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"proanthocyanins"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"color_intensity"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hue"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"od"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"proline"</span>)</span>
<span id="cb11-3"></span>
<span id="cb11-4"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">head</span>(data)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  alcohol malic_acid  ash alcalinity_ash magnesium total_phenols flavanoids
1       1      14.23 1.71           2.43      15.6           127       2.80
2       1      13.20 1.78           2.14      11.2           100       2.65
3       1      13.16 2.36           2.67      18.6           101       2.80
4       1      14.37 1.95           2.50      16.8           113       3.85
5       1      13.24 2.59           2.87      21.0           118       2.80
6       1      14.20 1.76           2.45      15.2           112       3.27
  nonflavanoids proanthocyanins color_intensity  hue   od proline   NA
1          3.06            0.28            2.29 5.64 1.04    3.92 1065
2          2.76            0.26            1.28 4.38 1.05    3.40 1050
3          3.24            0.30            2.81 5.68 1.03    3.17 1185
4          3.49            0.24            2.18 7.80 0.86    3.45 1480
5          2.69            0.39            1.82 4.32 1.04    2.93  735
6          3.39            0.34            1.97 6.75 1.05    2.85 1450</code></pre>
</div>
</div>
<p>The code below selects the relevant features from the dataset for clustering analysis. In this case, the features include measures of wine characteristics such as alcohol content, acidity, and phenolic compounds. The data[, 1:13] syntax extracts columns 1 to 13 from the data frame and assigns them to the features variable. After that we will perform partitional clustering using the k-means algorithm. The kmeans() function initializes the k-means algorithm with k=3 clusters, meaning that the data will be partitioned into three distinct groups. The algorithm iteratively assigns data points to the nearest cluster centroid, refining the clusters until convergence is reached.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Select features for clustering</span></span>
<span id="cb13-2">features <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> data[, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">13</span>]</span>
<span id="cb13-3"></span>
<span id="cb13-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the k-means algorithm with k=3 clusters</span></span>
<span id="cb13-5">kmeans <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">kmeans</span>(features, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span></code></pre></div>
</div>
<p>This line retrieves the cluster labels for each data point. The kmeans$cluster object contains the cluster assignments for all data points.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the cluster labels for each data point</span></span>
<span id="cb14-2">labels <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> kmeans<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>cluster</span></code></pre></div>
</div>
<p>This block generates a visualization of the k-means clustering results using the ggplot2 package. The plot displays the data points colored according to their cluster labels, revealing the groupings identified by the algorithm.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize K-means clustering</span></span>
<span id="cb15-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(data, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> alcohol, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">y =</span> malic_acid, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">factor</span>(labels))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb15-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb15-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"K-means Clustering (k=3)"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://akanksha-singh.us/posts/Clustering/index_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This block performs hierarchical clustering using Ward’s method. The hclust() function constructs a hierarchical tree structure based on the pairwise distances between data points. The dist(features) object calculates the distance matrix between all data points, and the method = “ward.D” argument specifies Ward’s method as the linkage method.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Perform hierarchical clustering using Ward's method</span></span>
<span id="cb16-2">hclust <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">hclust</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">dist</span>(features), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">method =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ward.D"</span>)</span></code></pre></div>
</div>
<p>This line generates a dendrogram, a tree-like structure that illustrates the hierarchical relationships between data points. The plot(hclust) function plots the dendrogram, showing the merging of clusters as the tree grows. This line cuts the dendrogram at a specific level to identify three clusters. The cutree() function extracts cluster labels from the dendrogram, and the k = 3 argument sets the number of clusters to extract</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Visualize hierarchical clustering using dendrogram</span></span>
<span id="cb17-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">plot</span>(hclust)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://akanksha-singh.us/posts/Clustering/index_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb18" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Cut the dendrogram at 3 clusters</span></span>
<span id="cb18-2">cut_hclust <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cutree</span>(hclust, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">k =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>)</span></code></pre></div>
</div>
</section>
<section id="applications-of-clustering" class="level2">
<h2 class="anchored" data-anchor-id="applications-of-clustering">Applications of Clustering</h2>
<p>Clustering algorithms find applications across diverse domains, including:</p>
<ul>
<li><p><strong>Customer segmentation:</strong> Clustering customer data can help identify distinct customer groups with shared characteristics, enabling targeted marketing campaigns.</p></li>
<li><p><strong>Image segmentation:</strong> Clustering algorithms can be used to segment images into meaningful regions, such as identifying objects in a scene.</p></li>
<li><p><strong>Anomaly detection:</strong> Clustering can be employed to detect anomalies in data by identifying data points that deviate significantly from the established clusters.</p></li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Clustering algorithms offer a powerful approach to uncovering hidden patterns and structures within unlabeled data. By grouping data points based on their inherent similarities, clustering techniques can provide valuable insights into the underlying relationships between data points. With the increasing availability of data, clustering algorithms are poised to play an increasingly important role in various fields, aiding in data exploration, pattern recognition, and decision-making.</p>


</section>

 ]]></description>
  <category>ml</category>
  <category>code</category>
  <category>analysis</category>
  <guid>https://akanksha-singh.us/posts/Clustering/index.html</guid>
  <pubDate>Fri, 24 Nov 2023 05:00:00 GMT</pubDate>
  <media:content url="https://akanksha-singh.us/posts/Clustering/clustering.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
